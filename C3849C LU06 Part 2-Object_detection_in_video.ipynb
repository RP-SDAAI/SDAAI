{"cells":[{"cell_type":"markdown","id":"7d4fccd4-56b8-4764-bf5a-c5b71f268c91","metadata":{"id":"7d4fccd4-56b8-4764-bf5a-c5b71f268c91"},"source":["# Video analysis using YOLOv5\n","\n","In this tutorial, you will apply the Object Detection model (YOLOv5) to a video."]},{"cell_type":"markdown","metadata":{"id":"NFH2CEkxXCJR"},"source":["---\n","### Mount to Google Drive\n","Mount to your Google Drive to access the images and model files."],"id":"NFH2CEkxXCJR"},{"cell_type":"code","metadata":{"id":"PLVF6gZ1XCnd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[],"id":"PLVF6gZ1XCnd"},{"cell_type":"code","metadata":{"id":"uC-SCxvX-FBP"},"source":["DataFolder = \"/content/drive/MyDrive/SDAAI/data\""],"execution_count":null,"outputs":[],"id":"uC-SCxvX-FBP"},{"cell_type":"markdown","id":"28e4ed66-4a3a-467b-ac06-8f8da0bf3bcc","metadata":{"id":"28e4ed66-4a3a-467b-ac06-8f8da0bf3bcc"},"source":["---\n","## Install the dependencies"]},{"cell_type":"code","execution_count":null,"id":"36102ec6-ca14-4b02-904c-c127c9c5c2d8","metadata":{"id":"36102ec6-ca14-4b02-904c-c127c9c5c2d8"},"outputs":[],"source":["# Install the necessary dependencies\n","!pip install opencv-python\n","!pip install glib\n","!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"]},{"cell_type":"markdown","id":"ac4cf8b0-3f0f-4805-98c3-0a201a97a44d","metadata":{"id":"ac4cf8b0-3f0f-4805-98c3-0a201a97a44d"},"source":["---\n","## Import the necessary libraries"]},{"cell_type":"code","execution_count":null,"id":"792086eb-aa23-414e-9c2a-cbfc74b9c852","metadata":{"id":"792086eb-aa23-414e-9c2a-cbfc74b9c852"},"outputs":[],"source":["import cv2\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm"]},{"cell_type":"markdown","id":"694fef1b-fc10-4c0c-ac25-6eb6b31c7eae","metadata":{"id":"694fef1b-fc10-4c0c-ac25-6eb6b31c7eae"},"source":["---\n","## Create the YOLOv5 model"]},{"cell_type":"code","execution_count":null,"id":"90e6f448-cc0f-4403-888e-52197468274d","metadata":{"id":"90e6f448-cc0f-4403-888e-52197468274d"},"outputs":[],"source":["# Import the neccesary libraries\n","import torch\n","\n","# Load the Model\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  "]},{"cell_type":"markdown","id":"fb910e8b-2211-48a3-930b-60eaff0966a1","metadata":{"id":"fb910e8b-2211-48a3-930b-60eaff0966a1"},"source":["---\n","## Define ```annotate_image()```\n","\n","Define a function to take in am RGB image, perform object detection on the image and return the annotated image."]},{"cell_type":"code","execution_count":null,"id":"824487be-7146-42b5-995c-4204763c7126","metadata":{"id":"824487be-7146-42b5-995c-4204763c7126"},"outputs":[],"source":["def annotate_image(image):\n","    \n","    # perform precidtion\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    results = model(image_rgb) \n","    \n","    for i in range(len(results.pandas().xyxy[0].name)):\n","      name = results.pandas().xyxy[0].name[i]\n","      startX = int(results.pandas().xyxy[0].xmin[i])\n","      startY = int(results.pandas().xyxy[0].ymin[i])\n","      endX = int(results.pandas().xyxy[0].xmax[i])\n","      endY = int(results.pandas().xyxy[0].ymax[i])\n","      confidence = results.pandas().xyxy[0].confidence[i]\n","      label = \"{}: {:.2f}%\".format(name, confidence * 100)\n","      if confidence > 0.6:\n","        cv2.rectangle(image, (startX, startY), (endX, endY),\n","                  (255,0,0), 2)\n","        y = startY - 15 if startY - 15 > 15 else startY + 15\n","        cv2.putText(image, label, (startX, y),\n","            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n","    \n","    return image    "]},{"cell_type":"markdown","id":"7e3ec050-b63b-4918-b51c-354bd285c84d","metadata":{"id":"7e3ec050-b63b-4918-b51c-354bd285c84d"},"source":["---\n","## Test the ```annotate_image()```"]},{"cell_type":"code","execution_count":null,"id":"869b68dc-0d35-4fec-b4c6-58518dd4381d","metadata":{"id":"869b68dc-0d35-4fec-b4c6-58518dd4381d"},"outputs":[],"source":["image = cv2.imread(DataFolder + '/LU04_images/zebra.jpg')\n","ann_image = annotate_image(image)\n","\n","image_display = cv2.cvtColor(ann_image, cv2.COLOR_BGR2RGB)\n","plt.imshow(image_display)\n","plt.show()"]},{"cell_type":"markdown","id":"b60cab4b-a006-412c-b69f-b643444decc7","metadata":{"id":"b60cab4b-a006-412c-b69f-b643444decc7"},"source":["---\n","Process the video file"]},{"cell_type":"code","execution_count":null,"id":"6db6c281-8af6-4113-9bda-942cc0058e25","metadata":{"id":"6db6c281-8af6-4113-9bda-942cc0058e25"},"outputs":[],"source":["video_in_file = DataFolder + \"/LU06_videos/Demo1.mp4\"\n","video_out_file = DataFolder + \"/LU06_videos/out.mp4\"\n","\n","print(\"[INFO] accessing video stream...\")\n","v_out = None\n","\n","v_in = cv2.VideoCapture(video_in_file)\n","total_frame = int(v_in.get(cv2.CAP_PROP_FRAME_COUNT ))\n","\n","for frame_no in tqdm(range(total_frame), desc=\"Processing Video...\"):\n","\n","  (grabbed, frame) = v_in.read()\n","\n","  # if the frame was not grabbed then we've reached the end of\n","  # the video stream so exit the script\n","  if not grabbed:\n","      print(\"[INFO] no frame read from stream - exiting\")\n","      break\n","          \n","  annotated_img = annotate_image(frame)\n","      \n","  # check if the video writer is None\n","  if v_out is None:\n","      # initialize our video writer\n","      fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n","      v_out = cv2.VideoWriter(video_out_file, fourcc, \n","                  int(v_in.get(cv2.CAP_PROP_FPS)),\n","                  (frame.shape[1], frame.shape[0]), True) \n","\n","  # write the output frame to disk\n","  v_out.write(annotated_img)\n","    \n","# release the file pointers\n","print(\"\\n[INFO] cleaning up...\")\n","v_out.release()\n","v_in.release()"]},{"cell_type":"markdown","source":["---\n","Play the out.mp4 file."],"metadata":{"id":"RKmUQCZSFL7m"},"id":"RKmUQCZSFL7m"},{"cell_type":"code","source":["video_mp4 = DataFolder + \"/LU06_videos/out_2.mp4\"\n","!ffmpeg -y -loglevel info -i $video_out_file -vf scale=640:480 $video_mp4"],"metadata":{"id":"ISR6NKXJGEg1"},"id":"ISR6NKXJGEg1","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"4ef3d216-1347-459c-93df-a506d4c7c95f","metadata":{"id":"4ef3d216-1347-459c-93df-a506d4c7c95f"},"outputs":[],"source":["def show_local_mp4_video(file_name, width=640, height=480):\n","  import io\n","  import base64\n","  from IPython.display import HTML\n","  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n","  return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n","                        <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n","                      </video>'''.format(width, height, video_encoded.decode('ascii')))"]},{"cell_type":"code","source":["show_local_mp4_video(video_mp4, width=640, height=480)"],"metadata":{"id":"Ed6GLjLXFNlB"},"id":"Ed6GLjLXFNlB","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9LK4_I2AUzPp"},"id":"9LK4_I2AUzPp","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"default:Python","language":"python","name":"conda-env-default-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}