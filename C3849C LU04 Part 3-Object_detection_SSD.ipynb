{"cells":[{"cell_type":"markdown","metadata":{"id":"C6y8_CXuGu9K"},"source":["# Perform Object Detection With Mobilenet-SSD in OpenCV\n","This tutorial is based on the following website: https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/"]},{"cell_type":"markdown","metadata":{"id":"NFH2CEkxXCJR"},"source":["---\n","### Mount to Google Drive\n","Mount to your Google Drive to access the images and model files."]},{"cell_type":"code","metadata":{"id":"PLVF6gZ1XCnd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uC-SCxvX-FBP"},"source":["DataFolder = \"/content/drive/MyDrive/SDAAI/data\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4aWctX9h8a0l"},"source":["---\n","## Import of libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N-SB3ntEGjjp"},"outputs":[],"source":["# import the necessary packages\n","import numpy as np\n","import cv2\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","print(cv2.__version__)"]},{"cell_type":"markdown","metadata":{"id":"biOPoNkE8jTb"},"source":["---\n","## Load the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABurVs6m8j4j"},"outputs":[],"source":["# load our serialized model from disk\n","print(\"[INFO] loading model...\")\n","prototxt_file = DataFolder+\"/LU04_Models/MobileNetSSD_deploy.prototxt.txt\"\n","model_file = DataFolder+\"/LU04_Models/MobileNetSSD_deploy.caffemodel\"\n","net = cv2.dnn.readNetFromCaffe(prototxt_file, model_file)"]},{"cell_type":"markdown","metadata":{"id":"Wi5eo8KC95UK"},"source":["---\n","### Load Image and prepare blob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3Vtfn2j94GS"},"outputs":[],"source":["# load the input image and construct an input blob for the image\n","# by resizing to a fixed 300x300 pixels and then normalizing it\n","# (note: normalization is done via the authors of the MobileNet SSD\n","# implementation)\n","image_file = DataFolder+\"/LU04_images/example_05.jpg\"\n","image = cv2.imread(image_file)\n","(h, w) = image.shape[:2]\n","blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)\n","\n","# show the input image\n","image_display = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(15, 15))\n","plt.imshow(image_display)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Cbd4Y6L193be"},"source":["---\n","### Perform object detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z991gGC5CzCi"},"outputs":[],"source":["%%time \n","# pass the blob through the network and obtain the detections and\n","# predictions\n","print(\"[INFO] computing object detections...\")\n","net.setInput(blob)\n","detections = net.forward()"]},{"cell_type":"markdown","metadata":{"id":"V7SdGljTDBf6"},"source":["---\n","### Loop through ```detections``` and draw bounding boxes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLv9HUwbDCNx"},"outputs":[],"source":["# initialize the list of class labels MobileNet SSD was trained to\n","# detect, then generate a set of bounding box colors for each class\n","CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n","    \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n","    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n","    \"sofa\", \"train\", \"tvmonitor\"]\n","\n","# set the minimum confidence to accept the detection\n","minimum_confidence = 0.6\n","\n","# loop over the detections\n","for i in np.arange(0, detections.shape[2]):\n","    # extract the confidence (i.e., probability) associated with the\n","    # prediction\n","    confidence = detections[0, 0, i, 2]\n","    # filter out weak detections by ensuring the `confidence` is\n","    # greater than the minimum confidence\n","    if confidence > minimum_confidence:\n","        # extract the index of the class label from the `detections`,\n","        # then compute the (x, y)-coordinates of the bounding box for\n","        # the object\n","        idx = int(detections[0, 0, i, 1])\n","        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n","        (startX, startY, endX, endY) = box.astype(\"int\")\n","        # display the prediction\n","        label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n","        print(\"[INFO] {}\".format(label))\n","        cv2.rectangle(image, (startX, startY), (endX, endY),\n","            (256,0,0), 2)\n","        y = startY - 15 if startY - 15 > 15 else startY + 15\n","        cv2.putText(image, label, (startX, y),\n","            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)"]},{"cell_type":"markdown","metadata":{"id":"oILx4WFjD9Xz"},"source":["---\n","### Display the object detections"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4YwLdHQD9_C"},"outputs":[],"source":["# show the output image\n","image_display = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(15, 15))\n","plt.imshow(image_display)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qN9lpeYETwR"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"default:Python","language":"python","name":"conda-env-default-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}